<h2>L2 Autonomous Driving</h2>
    <ul class="project-list">
         <li class="project-item" data-project-id="segmentation">
            <div class="project-content">
                <img src="assets/images/panoptic-segmentation/display.png" alt="segmentation">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                            Instance segmentation for vehicle automation
                        </h3>
                    </div>
                    <p>
                        Proposed using a CNN to directly generate the relationship matrix, 
                        replacing explicit computation to significantly reduce computational overhead.
                    </p>
                    <!-- <p>
                        This project was a continued work based on the lane detection project. The cooralationship matrix compustation is 
                        cumbersome, in this project, we changed the exact matrix computation to a full CNN network module to estimate the 
                        correlation matrix. And the use the estiamted matrix output for instance distinguishment. 
                    </p> -->
                    <div class="tech-list">
                        <span class="tech-item">Instance Segmentation</span>
                        <span class="tech-item">Pixel Level Relationship Matrix</span>
                        <span class="tech-item">Instance Distinguish Method</span>
                        <span class="tech-item">Bottom-up Algorithm</span>
                    </div>
                </div>
            </div>
        </li>
        <!-- Project 2 -->
        <li class="project-item" data-project-id="lane">
            <div class="project-content">
                <img src="assets/images/lane-detection/display.png" alt="Scene-depth">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                            Distinguish detected lane markers into sepearate lanes  
                        </h3>
                    </div>
                    <p>
                        Proposed an explicit relationship matrix following CNN-based feature extraction to distinguish individual lane instances. 
                        The method was deployed on in-vehicle driver-assistance systems for enhanced lane recognition.
                    </p>
                    <!-- <p>
                        This project motivated by solving the mutliple lane numbers lane detection problem.
                        I proposed to calcualte the pixel level pixel-pixel relationship matrix for distinguish from lane to lane markers.
                        The goal is to deal with on road lane level localization without high defination map available. 
                        reduced the computation load by filtering out the non lane marker pixels. 
                    </p> -->
                    <div class="tech-list">
                        <span class="tech-item">Pixel-pixel Relationship Matrix</span>
                        <span class="tech-item">Lane Detection</span>
                        <span class="tech-item">Unlimited Lane Numbers</span>
                        <span class="tech-item">Image Segmentation</span>
                    </div>
                </div>
            </div>
        </li>
        <!-- Project 3 -->
         <li class="project-item" data-project-id="detection">
            <div class="project-content">
                <img src="assets/images/vehicle-detection//display.png" alt="relative-motion">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                             Robust Thermal-RGB vehicle detection
                        </h3>
                        <p>
                            Developed a vehicle detection system using complementary RGB and thermal cameras to ensure 
                            robust performance under challenging lighting conditions.
                        </p>
                        <!-- <p>
                            This project motivated by the vehicle driving under servere lighting condition environment.
                            The servere lighting condition is common, such as: morning or dawn driving toward the sun, rainy night 
                            in a vary street lamp condition, low light condition, etc. 
                            These conditions significantly influnce the safety of driving. 
                            We proposed a complementry detection model using the far infrared camera and RGB camera, which can complement 
                            each other in different environment combinations which covers most of the driving scenarios: too bright of the 
                            visiable light, too dark of the visiable light, sheltered environemnt which uniforms the environemnt temps and the 
                            vehicle temps. 
                            Joint the info from RGB cam and thermal camera, we can detect the vehicle in most light conditon scenarios. 
                        </p> -->
                    </div><div class="tech-list">
                        <span class="tech-item">Thermal Camera</span>
                        <span class="tech-item">Vehicle Detection</span>
                        <span class="tech-item">Complementery Modality</span>
                        <span class="tech-item">Deep Learning</span>
                        <span class="tech-item">CNN</span>
                    </div>
                </div>
            </div>
        </li>
        <!-- Project 4 -->
         <li class="project-item" data-project-id="thermal-calibration">
            <div class="project-content">
                <img src="assets/images/thermal-rgb-calibration/display.png" alt="calibration">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                            Spatial calibration for thermal-rgb cameras and inertial sensor system 
                        </h3>
                        <p>
                            Proposed an LED-based thermal camera calibration board and a novel sub-pixel precision 
                            feature center localization method to improve thermal camera calibration accuracy.
                        </p>
                        <!-- <p>
                            This project is a prerequirement of themral rgb vehicle detection, we want to match the detected targets in 
                            one camera and the other.
                            In this project, the key to find a uniform marker that can be detected in both RGB camera and thermal camera.
                            So I designed a LED calibration board, which the light of the LED can be extract from RGB camera, and the temperature 
                            can be detected by the thermal camera. 
                            As the detection of the marker is different from the traditional camera calibration methods, the lighting LED is not a 
                            corner feature.In order to improve the detection accuracy, we proposed a Gaussian light and tempurature distribution model 
                            for better marker center estimation. 
                        </p> -->
                    </div><div class="tech-list">
                        <span class="tech-item">Thermal-RGB-IMU Camera Calibration</span>
                        <span class="tech-item">Gaussian Marker Distribution Model</span>
                        <span class="tech-item">LED Calibration Board</span>
                        <span class="tech-item">Real-scale Calibration</span>
                    </div>
                </div>
            </div>
        </li>
    </ul>
