<h2>Assistant Robot</h2>
    <ul class="project-list">
         <li class="project-item" data-project-id="ai-forestry">
            <div class="project-content">
                <img src="assets/images/leg-robot/display.gif" alt="segmentation">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                            Assistance Robot for Dementia Care 
                        </h3>
                    </div>
                    <p> In this paper, we proposed a coorelationship layer for instance segmenation. In order to distinguish individuls, we evaluate the relationship between every two position in the feature map. As this is a combination problem, this process is time consuming. Since the output still a tensor, we change the explicit evaluation method as CNN layer which geneate the relation map through network. And the explicit method provide the groud truth the relationship map layer. Then connect the relationshape layer to a MLP as </p>
                        <div class="tech-list">
                        <span class="tech-item">Computer Vision</span>
                        <span class="tech-item">IMU</span>
                        <span class="tech-item">Ego motion tracking</span>
                        <span class="tech-item">Feature scarcity scene tracking</span>
                    </div>
                </div>
            </div>
        </li>
        <!-- Project 2 -->
        <li class="project-item" data-project-id="ai-forestry">
            <div class="project-content">
                <img src="assets/images/laser-AR/display.gif" alt="Scene-depth">
                <div class="project-details">
                    <div class="project-title">
                        <h3>
                            Augmented Reality powered construction feild Lofting tool
                        </h3>
                    </div>
                    <p>This paper proposes a method to measure the motion of a moving rigid body using a hybrid visualâ€“inertial sensor. The rotational velocity of the moving object is computed from visual optical flow by solving a depthindependent bilinear constraint, and the translational velocity of the moving object is estimated by solving a dynamics constraint that reveals the relation between scene depth and translational motion. By fusing an inertial sensor, the scale of translational velocities can be estimated, which is otherwise unrecoverable from monocular visual optical flow. An iterative refinement scheme is introduced to deal with observation noise and outliers, and the extended Kalman filter is applied for motion tracking. The performance of the proposed method is evaluated by simulation studies and practical experiments, and the results show the effectiveness of the proposed method in terms of accuracy and robustness. </p>
                    <div class="tech-list">
                        <span class="tech-item">Real-scale depth estimation</span>
                        <span class="tech-item">Dense visual scene depth</span>
                        <span class="tech-item">IMU</span>
                        <span class="tech-item">Dense Optical flow</span>
                    </div>
                </div>
            </div>
        </li>
    </ul>
